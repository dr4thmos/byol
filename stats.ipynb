{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "m = torch.nn.LogSoftmax(dim=1)\n",
    "input = torch.randn(3, 4)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3946, -1.2349,  2.7990,  0.2295],\n",
      "        [-2.8446, -0.1938,  0.0765, -1.1852],\n",
      "        [ 0.1716, -2.1355,  1.0021, -0.2859]])\n",
      "tensor([[-3.3205, -4.1608, -0.1269, -2.6963],\n",
      "        [-3.6631, -1.0123, -0.7420, -2.0038],\n",
      "        [-1.3929, -3.7001, -0.5625, -1.8505]])\n"
     ]
    }
   ],
   "source": [
    "print(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COMPACT' 'DIFFUSE' 'DIFFUSE-LARGE' 'EXTENDED' 'FILAMENT' 'RADIO-GALAXY'\n",
      " 'RING' 'ARTEFACT']\n",
      "                                    source_name source_type survey telescope  \\\n",
      "count                                      4844        4844   4844      4844   \n",
      "unique                                     4844          82      2         2   \n",
      "top     G002.5+0.0IFx_Mosaic_Mom0_cutout0000001   [COMPACT]   mgps   meerkat   \n",
      "freq                                          1        2734   2704      2704   \n",
      "\n",
      "             project                                      original_path  \\\n",
      "count           4844                                               4844   \n",
      "unique             3                                               4844   \n",
      "top     lband-legacy  data/meerkat/G002/G002.5+0.0IFx_Mosaic_Mom0_cu...   \n",
      "freq            2704                                                  1   \n",
      "\n",
      "                                              target_path  \\\n",
      "count                                                4844   \n",
      "unique                                               4844   \n",
      "top     data/meerkat/G002/G002.5+0.0IFx_Mosaic_Mom0_cu...   \n",
      "freq                                                    1   \n",
      "\n",
      "                         one_hot  \n",
      "count                       4844  \n",
      "unique                        47  \n",
      "top     [1, 0, 0, 0, 0, 0, 0, 0]  \n",
      "freq                        2843  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:878: UserWarning: unknown class(es) ['BACKGROUND', 'BORDER', 'MOSAICING', 'WTF'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from data_utils.hulk import Hulk\n",
    "import numpy as np\n",
    "\n",
    "def remove_nan(im):\n",
    "    non_nan_idx = ~np.isnan(im)\n",
    "    min_image = np.min(im[non_nan_idx])\n",
    "    im[~non_nan_idx] = min_image\n",
    "    return im\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(remove_nan),\n",
    "    transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "dataset = Hulk(targ_dir = \"../4-HULK\", transform = transform\n",
    "               ,datalist=\"labeled.json\")\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std(dataloader):\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "    for data, _ in dataloader:\n",
    "        # Mean over batch, height and width, but not over the channels\n",
    "        channels_sum += torch.mean(data, dim=[0,2,3])\n",
    "        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
    "        num_batches += 1\n",
    "    \n",
    "    mean = channels_sum / num_batches\n",
    "\n",
    "    # std = sqrt(E[X^2] - (E[X])^2)\n",
    "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = get_mean_and_std(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=mean,\n",
    "                                 std=std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 256, 256])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "img should be Tensor Image. Got <class 'list'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m batch  \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m      7\u001b[0m     \u001b[39mprint\u001b[39m(batch[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> 8\u001b[0m     grid \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mmake_grid(normalize(batch))\n\u001b[1;32m      9\u001b[0m     img \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mToPILImage()(grid)\n\u001b[1;32m     10\u001b[0m     img\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torchvision/transforms/transforms.py:270\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, tensor: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    263\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mnormalize(tensor, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmean, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstd, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torchvision/transforms/functional.py:358\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    356\u001b[0m     _log_api_usage_once(normalize)\n\u001b[1;32m    357\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(tensor, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 358\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimg should be Tensor Image. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(tensor)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    360\u001b[0m \u001b[39mreturn\u001b[39;00m F_t\u001b[39m.\u001b[39mnormalize(tensor, mean\u001b[39m=\u001b[39mmean, std\u001b[39m=\u001b[39mstd, inplace\u001b[39m=\u001b[39minplace)\n",
      "\u001b[0;31mTypeError\u001b[0m: img should be Tensor Image. Got <class 'list'>"
     ]
    }
   ],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "#examples = next(iter(dataloader))\n",
    "\n",
    "for batch  in dataloader:\n",
    "    print(batch[0].shape)\n",
    "    grid = torchvision.utils.make_grid(normalize(batch[0]))\n",
    "    img = torchvision.transforms.ToPILImage()(grid)\n",
    "    img.show()\n",
    "    #examples = nex-t(iter(dataloader))\n",
    "    #plt.imshow(grid)\n",
    "    #plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  7 2022, 04:19:52) \n[GCC 10.2.1 20210110]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
